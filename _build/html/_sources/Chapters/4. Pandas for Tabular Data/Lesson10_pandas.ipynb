{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75dbfd7d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"https://github.com/pandas-dev/pandas/raw/main/web/pandas/static/img/pandas.svg\" alt=\"pandas Logo\" style=\"width: 800px;\"/></center>\n",
    "\n",
    "# Lessons 10 - 14 : Pandas Primer\n",
    "\n",
    "This lesson is modified from [Introduction to Pandas](https://foundations.projectpythia.org/core/pandas/pandas.html) by [Project Pythia](https://projectpythia.org), and from  [Exploring data using Pandas](https://geo-Python-site.readthedocs.io/en/latest/notebooks/L5/exploring-data-using-pandas.html), [Processing data with Pandas](https://geo-Python-site.readthedocs.io/en/latest/notebooks/L5/processing-data-with-pandas.html), [Processing data with Pandas II](https://geo-Python-site.readthedocs.io/en/latest/notebooks/L6/advanced-data-processing-with-pandas.html) by [Geo-Python](https://geo-Python-site.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/aselshall/eds/HEAD)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b47505",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "From the [official documentation](https://pandas.pydata.org/), Pandas “is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language.” Pandas is a powerful library for working with tabular data. You can think of it as a programmable spreadsheet. By the end of this lesson you will be able to: \n",
    "- install and import Pandas\n",
    "- import a csv file with Pandas \n",
    "- use Pandas for exploratory data analysis\n",
    "- filter and query through data to perform data analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c795c07",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065816f7-4076-4384-b24c-621387f8033b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Cheat Sheets\n",
    "\n",
    "- Basic: [1-page cheat sheet by Data Camp](https://assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf)\n",
    "- Advanced: [2-page cheat sheet by Pandas Developers](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)\n",
    "- Comprehensive: [12-page cheat sheet by Lee at Univ of Idaho](https://www.webpages.uidaho.edu/~stevel/cheatsheets/Pandas%20DataFrame%20Notes_12pages.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354011f1-0e6c-4c92-9c5c-95b6b8ab65c0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcc8575-6af7-4b78-ac83-e12f340af7a7",
   "metadata": {},
   "source": [
    "## 1. Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010b5c8e-383c-4339-92f8-87fa4cc438f0",
   "metadata": {},
   "source": [
    "If you are using anaconda, you do not need to install Pandas. If you just installed Python only, then need to install these common packages such as Pandas and numpy. You can [Install panda](https://pandas.pydata.org/docs/getting_started/install.html) using pip\n",
    "```Python\n",
    "pip install pandas\n",
    "```\n",
    "Before you type to above command in a new code cell, you can update your pip and install a dependancy.\n",
    "\n",
    "Just run these cells one by one. After each the installation is complete, make sure to restart the kernel from the menu `Kernel`:`Restart Kernel...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8446fcb-3d97-4941-8d9e-9bf68bd1ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fb0b93-98cb-4854-8e47-3fe9fb366bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2239fd-d40e-4da9-9754-c36b331e1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3b6ab6-e38e-4c4b-b889-f1f5b67f4d29",
   "metadata": {},
   "source": [
    "You need to install these once. Then you can comment the installation command (as they are already commented above) or delete these cells to avoid repeating this ever time your run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce8b269",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024f3425",
   "metadata": {},
   "source": [
    "You will often see the nickname `pd` used as an abbreviation for Pandas in the import statement, just like `numpy` is often imported as `np`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b28a4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a06dd8a5-ae60-4c39-bd30-47b970ef8d24",
   "metadata": {},
   "source": [
    "Note as a good coding practice, we generally import all the packages that we will need in the first cell in our notebook. However, we are importing Pandas here in the middle of our notebook for educational purpose. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73e6859-acb7-48a2-a791-53f706c276b3",
   "metadata": {},
   "source": [
    "## 3. Basic terminologies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7153822",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "The Pandas [`DataFrame`](https://Pandas.pydata.org/docs/user_guide/dsintro.html#dataframe) and The Pandas [`Series`](https://Pandas.pydata.org/docs/user_guide/dsintro.html#series) are **labeled** data structures. \n",
    "\n",
    "The Pandas [`DataFrame`](https://Pandas.pydata.org/docs/user_guide/dsintro.html#dataframe) (a 2-dimensional data structure) is used for storing and mainpulating table-like data (data with rows and columns) in Python. You can think of a Pandas DataFrame as a programmable spreadsheet.\n",
    "\n",
    "![dataframe schematic](https://github.com/Pandas-dev/Pandas/raw/main/doc/source/_static/schemas/01_table_dataframe.svg \"Schematic of a Pandas DataFrame\")  \n",
    "The first column in dark gray, referred to as an `index`, contains information characterizing each row.   \n",
    "The first row in dark gray, referred to as `header`, contains the column lablels\n",
    "\n",
    "The Pandas [`Series`](https://Pandas.pydata.org/docs/user_guide/dsintro.html#series) (a 1-dimensional data structure) is used for storing and manipulating a sequence of values. Pandas Series is kind of like a list, but more clever. One row or one column in a Pandas DataFrame is actually a Pandas Series.\n",
    "\n",
    "![Pandas Series](https://github.com/Pandas-dev/Pandas/raw/main/doc/source/_static/schemas/01_table_series.svg \"Schematic of a Pandas Series\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e84c8a-cbea-44f3-9dc5-d0386ceac779",
   "metadata": {},
   "source": [
    "## 4. Learning Pandas by an example\n",
    "\n",
    "Let us learn Pandas by an example. This is mainly to \n",
    "- gain an understanding of how to effectively use the library in your own projects\n",
    "- showcase the wide range of capabilities\n",
    "- accelerate the learning process\n",
    "\n",
    "The idea here is to empower you to adapt these tools to various data analysis tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6ddef8-443b-453d-9c1a-a2acc0450339",
   "metadata": {},
   "source": [
    "### 4.1 Collecting weather data\n",
    "\n",
    "Let us go to [NOAA](https://www.ncdc.noaa.gov/cdo-web) to collect weather data for Fort Myers area from Jan 1, 2020 to Dec 31, 2023. Go to [Browse Datasets](https://www.ncdc.noaa.gov/cdo-web/datasets) and then select [Normals Daily: Search Tool](https://www.ncei.noaa.gov/cdo-web/search?datasetid=NORMAL_DLY). Then make the following selections:\n",
    "- Select Weather Observation Type/Dataset :  Daily Summaries\n",
    "- Select Date Range : 2020-01-01 to 2023-12-31\n",
    "- Search For : Cities\n",
    "- Enter a Search Term : Fort Myers\n",
    "\n",
    "Then add to cart 'Fort Myers, FL US' and checkout your data as 'Custom GHCN-Daily CSV'.\n",
    "\n",
    "On your checkout select the following\n",
    "- [x] Station Name\n",
    "- [x] Geographic Location\n",
    "- [ ] Include Data Flags\n",
    "\n",
    "Show All / Hide All | Select All / Deselect All\n",
    "- [x] Precipitation\n",
    "- [x] Air Temperature\n",
    "- [x] Wind\n",
    "- [x] Weather Type\n",
    "\n",
    "Then submit your order. Wait for a minute or so until your data is ready. Download your data. It is always a good idea to download the data documentation to get a better understanding of your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918dc132-1b42-41f9-bce9-36cf2bcd4e74",
   "metadata": {},
   "source": [
    "### 4.2 Importing a `csv` file\n",
    "We start by reading in some data in comma-separated value (`.csv`) format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61d212b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Once we have a valid path to a data file that Pandas knows how to read, we can open it with:\n",
    "``` Python\n",
    "dataframe_name = pd.read_csv('filepath/your_file.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d155990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a csv file with Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9fdcfb-6edb-40e5-b12d-6f337f227fab",
   "metadata": {},
   "source": [
    "### 4.3 Displaying a `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6007cc3a",
   "metadata": {},
   "source": [
    "#### 4.3.1 Display DataFrame\n",
    "\n",
    "If you are using a Jupyter notebook, do not use `print(df)`. Jupyter can display a nicely rendered table by just typing your dataframe_name or `display(dataframename)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c8f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display your DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c8514c-acde-4b10-8d14-bcc58a295aaf",
   "metadata": {},
   "source": [
    "In order to flood your screen, Jupyter did not print the whole table to screen. You can play with what you want to view. For example, try playing with these dataframe methods `df.head()`, `df.head(3)`, `df.tail(8)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3769aabb-e524-49f1-aacc-484af064c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first few columns in your DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d63332-6505-4519-b3fc-5db15589bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first three rows in your DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbf44e1-5b55-4432-bd93-e98dffb73260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the last few rows in your DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7544da9-bec8-4b29-b94d-59219cf258b5",
   "metadata": {},
   "source": [
    "#### 4.3.2 Display the size of DataFrame\n",
    "\n",
    "You can learn about the number of rows and column in a dataFrame using `df.shape`, number of rows `df.shape[0]` and numbers of columns `df.shape[1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e39ce9-e439-4908-8522-444a138c3ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show number of rows and columns in your DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b234b2b-bed9-40f2-82f6-a7eb79680d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show number of rows in your DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8626510-47e3-41f6-9547-b3126b15a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show number of columns in your DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec363240-374e-4fe8-9490-fac1b88f30b7",
   "metadata": {},
   "source": [
    "#### 4.3.3 Display different date types in your DataFrame\n",
    "\n",
    "Let's check the datatype of columns 'PRCP', 'STATION', and 'DATE\" using `df['column_label'].dtypes` or `df.column_label.dtypes` \n",
    "\n",
    "The data type dtype('O') indicates that the Pandas column contains objects, typically strings, rather than numerical or datetime values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f6285-6882-4d41-b318-b429a9e2bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data type for column PRCP \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd5ea7f-449f-4edc-8e8f-df75498d35ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data type for column STATION \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e077c66b-6c76-4d00-8bf6-502edba6e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data type for column DATE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74d4382-c7aa-4742-a6cc-4ab8c0118f7a",
   "metadata": {},
   "source": [
    "#### 4.3.4 Change data type in your DataFrame\n",
    "\n",
    "Pandas did not recognize `DATE` as datetime format. To convert a column in a Pandas DataFrame to datetime format, you can use the \n",
    "```python\n",
    "df[column_name]=pd.to_datetime(column_name)\n",
    "```\n",
    "function. Here's how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b2f45-30c3-48fa-acea-ffb6a396dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert format of DATE to datetime format\n",
    "\n",
    "\n",
    "#Data type for column DATE using .dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363a946a-3c0f-4352-935e-53d9366f7bea",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Note</p>\n",
    "    Changing date types in Pandas is not uncommon because sometime Pandas cannot automatically format your data as you expect it, so you need to convert the data format manually as we did above.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ead6b8e-3966-404d-b797-cddbb825cc95",
   "metadata": {},
   "source": [
    "### 4.4 Filter columns by column labels\n",
    "\n",
    "My data has 24 columns and I want to focus only on these columns\n",
    "\n",
    "| Column Label | Description |\n",
    "|--------------|-------------|\n",
    "| STATION      | Station identification code (17 characters). |\n",
    "| NAME         | Name of the station (usually city/airport name, max 50 characters). |\n",
    "| DATE         | Year of the record (4 digits) followed by month (2 digits) and day (2 digits). |\n",
    "| PRCP         | Precipitation (mm or inches as per user preference, inches to hundredths on Daily Form pdf file) |\n",
    "| TMAX         | Maximum temperature (Fahrenheit or Celsius as per user preference, Fahrenheit to tenths on Daily Form pdf file) |\n",
    "| TMIN         | Minimum temperature (Fahrenheit or Celsius as per user preference, Fahrenheit to tenths on Daily Form pdf file) | \n",
    "| AWND         | Average daily wind speed (meters per second or miles per hour as per user preference) |\n",
    "\n",
    "\n",
    "  \n",
    "You can use the statement `df = df[selected_columns]` to select and update the DataFrame df to contain only the columns specified in the list selected_columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37feb9-6501-4569-9610-da487f917dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of column names to focus on\n",
    "selected_columns = ['STATION', 'NAME', 'DATE', 'PRCP','TMAX', 'TMIN', 'AWND']\n",
    "\n",
    "# Filter the DataFrame to include only the selected columns\n",
    "\n",
    "\n",
    "# Display new DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c99cec-011b-4b4b-acc1-ece81c93cee4",
   "metadata": {},
   "source": [
    "### 4.5 Filter rows by a keyword  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ecba5b-1112-4c77-a44c-87096e084f0a",
   "metadata": {},
   "source": [
    "I only want stations at airports. You can filter a DataFrame based on whether a particular column contains a specific string using\n",
    "```python\n",
    "df[column_name].str.contains(keywords)`\n",
    "```\n",
    "method in Pandas. \n",
    "\n",
    "In other words, I want to see which rows in the column `df['NAME']` that contains the keyword 'Airport', and only retain these rows and filter out all other rows. Here is how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d440aa-b8c0-4e89-b749-1abe2789c912",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify the keyword you want to filter for in the 'NAME' column\n",
    "keyword = 'AIRPORT'\n",
    "\n",
    "#Use Pandas method str.contains() to create a boolean mask, \n",
    "# which is `True` for rows where the `NAME` column contains the specified keyword.\n",
    "\n",
    "\n",
    "# Display your mask for understanding\n",
    "\n",
    "\n",
    "# Use this mask to filter the DataFrame; that is to update it with the desired condition\n",
    "\n",
    "\n",
    "# Print the resulting DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445497d1-97b6-4bbe-9847-fc30abeb2b00",
   "metadata": {},
   "source": [
    "#### Showing unique values in a column \n",
    "\n",
    "How many stations do I have in that column after updating my DataFrame with that keyword?\n",
    "\n",
    "To find unique values in a specific column, in this case, the `NAME` column of a DataFrame, you can use the `.unique()` method in Pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d00f0df-9420-4f97-9fc9-c29f7bcbd3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display unique station names in 'NAME'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a0775-03c3-4014-b621-dc55b9e7e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display unique station IDs in 'STATION'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6b8378-7376-4b5d-b471-b063a21b333a",
   "metadata": {},
   "source": [
    "### 4.6 Filter rows by a specific value\n",
    "\n",
    "If you want to filter your DataFrame to only include rows where the `STATION` column has the value 'USW00012835', you can also use boolean indexing. \n",
    "```python\n",
    "df['STATION'] == 'USW00012835'\n",
    "```\n",
    "\n",
    "Let us do this here and let use save this a new DataFrame `one_station` by using `.copy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df619dd1-df4d-4f0a-bd89-d4f98684da73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Use Pandas create a boolean mask with name station_mask \n",
    "#for all rows that the column `STAINION` has value of 'USW00012835'\n",
    "\n",
    "# Use the station_mask  to filter DataFrame for rows where 'Station' is 'USW00012835' and save it to a new DataFrame 'one_station'\n",
    "\n",
    "\n",
    "# Print the resulting DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef01602c-be85-457f-be43-5f8702c7d4cb",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Note</p>\n",
    "    When using <code>.copy()</code>, you explicitly create a new DataFrame ensuring that modifications to new DataFrame do not affect the original DataFrame <code>df</code>. In other words, you clearly tell Pandas that you want an independent copy of the data and not just a different view.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed287a-3fe1-42e8-b3da-ef18df9432c4",
   "metadata": {},
   "source": [
    "Now I have the data for one station for my study period. While my header is informative, my index is not informative. We generally make date-time as our index as shown next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d002c484-37a5-4eea-8213-eb5872e12352",
   "metadata": {},
   "source": [
    "### 4.7 Make a datetime column as the DataFrame index\n",
    "\n",
    "To make the `DATE` column as the index of your DataFrame, you can use:\n",
    "```Python \n",
    "# Note: inplace=True argument will modify the DataFrame directly, instead of creating a new one\n",
    "df.set_index('Date_Column_Name',inplace=True) \n",
    "``` \n",
    "\n",
    "However, before we set our `DATE` column as our index column, let us change its format to datetime format. We already did this conversion [above](#4.3.4-Change-data-type-in-your-DataFrame), but let us do it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be53a18-537d-4b7d-b622-01f950e2d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the \"DATE\" column to datetime format using pd.to_datetime()\n",
    "\n",
    "\n",
    "# Set the \"DATE\" column as the index of your DataFrame\n",
    "\n",
    "\n",
    "#Display your DataFrame with `DATE` as index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5103114-6494-4cfa-8afa-f1d332294144",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Note</p>\n",
    "    Pandas may or may not understand the format of <code>DATE</code> column as date. Thus, it is generally a good practice to convert the column to datetime format before setting it as the index, especially if you plan to perform time-based operations later on. If the column is not in datetime format, some time-related functionalities may not work correctly.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a042a9cb",
   "metadata": {},
   "source": [
    "#### Check the index\n",
    "\n",
    "Now let us see how the index change of our original DataFrame `df.index` and the one we just modified `one_station.index`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a57e30c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Index of the original DataFrame df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c0688-4799-4ece-b949-d705ac16939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index of the DataFrame one_station after we changed its index to be the DATE column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283460e8-1b6b-4ca5-93e4-7a39d827f2d2",
   "metadata": {},
   "source": [
    "You can also show the range of your index with `.index.min()` and `.index.max()` methods. \n",
    "\n",
    "Try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7fb52b-f172-4bb9-bbfe-b24c97c3bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print min index value in DataFrame df\n",
    "\n",
    "#Print max index value in DataFrame df\n",
    "\n",
    "#print min index value in DataFrame one_station\n",
    "\n",
    "\n",
    "#Print max index value in DataFrame one_station\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025cd849-58fb-4561-b712-edc0b0d38c12",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Note</p>\n",
    "    You might be wondering why the index of <code>df</code> is not starting from <code>0</code>. That is because we already have removed some rows from it, so the retained rows retain their original index values. If you do not want this, you can reset your index using  <code>df = df.reset_index()</code>. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a96fe5-9862-4893-89a8-492a49171ea5",
   "metadata": {},
   "source": [
    "Try looking at the label of column by using: `one_station.columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb69226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print column labels in DataFrame one_station\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444aecb5-cf19-411c-8932-33ffb27c3844",
   "metadata": {},
   "source": [
    "### 4.8 Descriptive statistics\n",
    "\n",
    "Pandas DataFrames contain useful methods for getting summary statistics. Available methods include `describe()`, `info()`, `count()`, `mean()`, `median()`, `min()`, `max()`, and `std()` (the standard deviation). You can also do `column_name.describe()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c3869d-4713-4407-828b-69e1477f143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics for one_station Dataframe\n",
    "one_station.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8079abe0-86c7-4e47-884e-248e8c4c6c9f",
   "metadata": {},
   "source": [
    "You can also do it per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62630b57-9dc7-4863-94be-7bb5964f196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics for the column 'PRCP' one_station Dataframe (dot notation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04089fd-2e55-4dbf-82f7-04df2a74f7ee",
   "metadata": {},
   "source": [
    "You can also use dic notation `one_station['PRCP']` instead of dot notation `one_station.PRCP`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac29f756-e57a-4bc0-9daa-f949e3bccf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics for the column 'PRCP' one_station Dataframe (dic notation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2619825-82d3-4eb3-98b5-a59507185520",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Note</p>\n",
    "     The dot notation will not work if the column name is not a valid variable name (e.g., having space, starting with a number, etc.).\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922b38e7-c0fb-4571-a965-6214d6e1714a",
   "metadata": {},
   "source": [
    "You can do it per a group of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc94e0bf-6203-4970-81af-23d1e0350ace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List of columns to show\n",
    "columns_group = ['PRCP', 'AWND']\n",
    "\n",
    "#Descriptive statistics for a selected columns in one_station Dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fea0db1-efac-4cc0-bc31-225bfb9ee7a7",
   "metadata": {},
   "source": [
    "### 4.9 Resampling of time-series data\n",
    "\n",
    "Remember Pandas is powerful because it is a programmable spreadsheet. For example, can to find the min, max, mean, or median value per month, week, year, or any other criteria. You can use the method of \n",
    "```python\n",
    "df.resample(\"Freqency\").arreegation_method()\n",
    "```\n",
    "Frequency: The target frequency you want to resample to. Pandas supports many frequencies:\n",
    "- \"D\" - Calender day\n",
    "- \"B\" - Business day \n",
    "- \"M\" - Monthly frequency\n",
    "- \"W\" - Weekly frequency \n",
    "-  \"h\" - Hourly frequency\n",
    "-  \"min\" - Minutely frequency\n",
    "\n",
    "and  many more as shown in [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects).\n",
    "\n",
    "Aggregation Methods: When downsampling, you often want to summarize groups of data using Pandas provided methods such as:  \n",
    "- `mean()` - Calculates the mean\n",
    "- `sum()` - Calculates the sum\n",
    "- `min()` - Finds the minimum value\n",
    "- `max()` - Finds the maximum value\n",
    "- `std()` - Calculates standard deviation\n",
    "\n",
    "... and others\n",
    "\n",
    "For example, find the max PRCP, TMAX, TMIN and AWND for each week in your dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd7363c-3c3e-42c0-bf2d-25cacaa6a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Max PRCP, TMAX, TMIN and AWND in every week of my dataset using .resample() method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ed5c5-7f2d-4c35-9f9a-31fb70db207d",
   "metadata": {},
   "source": [
    "Find the min PRCP, TMAX, TMIN and AWND in each year in my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9805de-4bf0-4205-863e-7cbdd0329820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min PRCP, TMAX, TMIN and AWND in each year .resample() method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243cafeb-318a-4aac-880a-08afdca4b74d",
   "metadata": {},
   "source": [
    "This is mainly a quick overview on `.resample()` method. To learn this method in details, check [Pandas user-guide on resampling](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92651ede-47f3-4b93-9ed0-f044f5437acf",
   "metadata": {},
   "source": [
    "### 4.10 Groupby \n",
    "\n",
    "While resample is specifically designed to change the frequency of the time series, groupby is a more general-purpose tool for grouping data based on some criteria, which can include time-related criteria but is not limited to time-series data. It can be used with any categorical or numerical criteria for grouping. It's more flexible and allows for custom aggregation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d0fa23-c926-481e-be66-ee476df3ca99",
   "metadata": {},
   "source": [
    "#### 4.10.1 Groupby for categorical data\n",
    "\n",
    "For example, what if we want to find the monthly mean of `TMAX` and `TMIN` for the two weather stations at two airports. Let us first create the DataFrame `two_stations` for these two weather stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea250b1-398b-4c9a-8e84-72cac036f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new DataFrame contains only stations at airports\n",
    "two_stations = df.copy()\n",
    "\n",
    "# Convert the \"DATE\" column to datetime format\n",
    "two_stations['DATE'] = pd.to_datetime(two_stations['DATE'])\n",
    "\n",
    "# Set the \"DATE\" column as the index of your DataFrame\n",
    "two_stations.set_index('DATE', inplace=True)\n",
    "\n",
    "#Display data for two stations\n",
    "two_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f359c4bb-bdcf-4f1f-b91e-9acfa98592f6",
   "metadata": {},
   "source": [
    "We can see that we have two stations \"USW00012894\" and \"USW00012835\". \n",
    "  \n",
    "We can to find the monthly mean of our data. However, if you tried to apply a method such as `mean()` or `resample()` as we did before in [Secion 4.9](#4.9-Resampling-of-time-series-data) you will get an error\n",
    "```Python\n",
    "TypeError: agg function failed [how->mean,dtype->object]\n",
    "```\n",
    "suggesting that that you have non-numeric columns in your DataFrame, and the `mean()` operation is not applicable to those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9decd3f1-6d3a-47b4-bd04-0819f3f3e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This commented code will give you an error because two_stations has non-numeric data\n",
    "#two_stations.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1411452f-bdab-47ba-be55-b9b4b3f691b8",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Note</p>\n",
    "      In case you are wonder, why did the <code>.mean()</code> method worked with the <code>one_station</code> DataFrame, but not with <code>two_stations</code> DataFrame even although the <code>one_station</code> also contained non-numeric values in columns <code>NAME</code> and <code>STATION</code>?  In  <code>one_station</code> DataFrame the values in non-numeric columns were not changing because it is only one station. But with <code>two_stations</code> DataFrame the values in the non-numeric columns <code>NAME</code> and <code>STATION</code> are chaning because we have two stations. Thus, we cannot apply the <code>.mean()</code> method. In other words, what is the mean of \"USW00012894\" and \"USW00012835\" ?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f74ba71-1b3e-41f2-ae78-03cfb8a796f5",
   "metadata": {},
   "source": [
    "Thus, before using `resample()` and `mean()`, it's a good idea to ensure that all columns you're aggregating are numeric. \n",
    "\n",
    "Let us filter out `STATION` and `NAME` that are the non-numeric columns, and only keep the numeric columns that are `PRCP`,\t`TMAX`,\t`TMIN`, and `AWND`. For filtering out, you can do `two_stations[columns_to_keep]` as we learned [before in Section 4.4](#4.4-Filter-columns-by-column-labels).  Then we can apply the `.mean()` , `.resample('Y').mean()` , or whatever method you need to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfd189d-d972-4ea8-9bb9-a10c75aed56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the numeric columns that you want\n",
    "columns_to_keep =  ['PRCP', 'TMAX', 'TMIN', 'AWND']\n",
    "\n",
    "#Apply mean to numeric columns \n",
    "two_stations[columns_to_keep].resample('Y').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea08b86-4bac-48a1-95ad-34741ca6de7a",
   "metadata": {},
   "source": [
    "The above method works, but using \n",
    "```python\n",
    "df.groupby(groupby_column)[columns_to_show].method_you_need()\n",
    "```\n",
    "can be more pwoerful because it will show you these values for each category, which is in that case for each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afbc6fa-4a7e-481f-a607-06d2033caf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select columns only\n",
    "columns_to_keep =  ['PRCP', 'TMAX', 'TMIN', 'AWND']\n",
    "\n",
    "# For the two_stations DataFrame group by 'STATION' then apply .resample('Y').mean() to the selected columns only\n",
    "# groupy-> Select columns -> apply method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce7468-fa51-4ea4-a510-e0bb41d3d7f3",
   "metadata": {},
   "source": [
    "Try to do it again, but this time groupby 'NAME` or both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb71b5-d941-498f-b4c8-65eece5c3ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select columns only\n",
    "columns_to_keep =  ['PRCP', 'TMAX', 'TMIN', 'AWND']\n",
    "\n",
    "# For the two_stations DataFrame group by 'STATION' then apply .resample('Y').mean() to the selected columns only\n",
    "# groupy-> Select columns -> apply method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ff1c7d-f890-456e-a58f-dbe11ca4a7bb",
   "metadata": {},
   "source": [
    "### 4.11 Slicing with loc and iloc\n",
    "\n",
    "Slicing is a method used to extract a subset of data from a larger data structure, such as a list, array, or DataFrame, by specifying a range or specific indices.ases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500862d0-6dc9-433e-abee-b5b75969f517",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "The following two ways to access data are preferred by Pandas over other methods:\n",
    "1. For `.loc[\"row_start\":\"row_end\", \"col_start\":\"col_end\"]`:\n",
    "    - `.loc[]`: Access data by label.\n",
    "    - `\"row_start\":\"row_end\"`: Specify the range of rows by their labels, inclusively.\n",
    "    - `\"col_start\":\"col_end\"`: Specify the range of columns by their labels, inclusively.\n",
    "\n",
    "2. For `.iloc[row_start:row_end, col_start:col_end]`:\n",
    "    - `.iloc[]`: Access data by index position.\n",
    "    - `row_start:row_end`: Specify the range of rows by their index positions, exclusively.\n",
    "    - `col_start:col_end`: Specify the range of columns by their index positions, exclusively.\n",
    "\n",
    "The `.loc[]` method when accessing data by label is inclusive, meaning it includes the specified start and end labels.  \n",
    "The `iloc[]` method when accessing data by index is exclusive, meaning it includes the start index but excludes the end index.\n",
    "  \n",
    "The above is a general syntax, but there are some many special cases.ases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58ea812-6780-4b39-b474-cab0ccdab473",
   "metadata": {},
   "source": [
    "#### 4.11.1 Slicing with `loc`\n",
    "\n",
    "Let us slice from index label `2023-12-30` to `2023-12-31` and column labels `STATION` to `PRCP`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d84cec-8a7b-4caf-bc9e-bb5acdb27066",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Note</p>\n",
    "In Pandas, to perform a value-based partial slicing operation, your DataFrame index need to sorted in ascending order. You can do this using <code>.sort_index(inplace=True)</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2b4ae-e0a2-427d-a723-a42878bedbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the two_stations DataFrame by the 'DATE' index in ascending order\n",
    "two_stations.sort_index(inplace=True)\n",
    "\n",
    "# View last 5 rows in two_stations DataFrame\n",
    "\n",
    "# View  slice from '2023-12-30' to'2023-12-31', and 'from STATION' to 'PRCP' using loc (inclusive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6602cd8f-a2d8-4f02-a82f-fc835d720fee",
   "metadata": {},
   "source": [
    "You can also do `'2023-12:30':` to retrieve all rows from the specified start date `2023-12-30` to the end of the last row. You can also do the same for columns `'STATION':` if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510c49d6-4e56-41e2-9e23-e845d515b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In two_stations DataFrame, view  slice from '2023-12-30' to the last row, and 'from STATION' to the last column using loc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9746eeb-009f-4137-b66a-55787a2d027d",
   "metadata": {},
   "source": [
    "You can also specify what you exactly `['NAME','STATION','PRCP']` need instead of having a range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e40ff03-351c-45e4-9d8b-24d5c7347894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In two_stations DataFrame, view slice from '2023-12-30' to the last row, and for clumns 'NAME','STATION', and'PRCP' in that order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c06ba5-65de-40c8-a2d8-e93cebc0f36b",
   "metadata": {},
   "source": [
    "##### Special case for a datetime index\n",
    "\n",
    "If your index is datetime you can even do more, like slicing a certain year.\n",
    "\n",
    "For example let us say I want to slice the data of 2023. It is very simple `.loc['2023']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efe5318-e284-4253-9e3b-68ad49ca03b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slice 2023 data in two_stations DataFrame using .loc[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7a8223-6409-4147-8eb9-3e7c99dd9c15",
   "metadata": {},
   "source": [
    "#### 4.11.2 Slicing with `iloc`\n",
    "\n",
    "Do the same with `iloc`, and slice from rows `2023-12-30` to `2023-12-31` and columns `STATION` to `PRCP`. \n",
    "\n",
    "First find the shape of this DataFrame to get an idea about the index number for the last four rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977bb2de-95e4-4eed-b409-d9b045438d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the shape of two_stations DataFrame first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da5ead-b4da-4a22-8e1f-a6e5344f789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View  slice from '2023-12-30' to'2023-12-31', and 'from STATION' to 'PRCP' using iloc (exclusive) starting from 2918:2922\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdcb202-62ea-450d-a979-4376a9cbf218",
   "metadata": {},
   "source": [
    "You can also do `2918:` to retrieve all rows from the specified index to the end of the last index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61229b0-ecfc-4e52-b5ba-7326f7fd3861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View  slice from '2023-12-30' to the last row, and from 'STATION' to the last column using iloc (exclusive) starting from 2918\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc3842-f3d2-42eb-b0ee-0445ddedc15d",
   "metadata": {},
   "source": [
    "In the above example, since you are starting from index `0` you can just do `:` which will select all columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a395c8a9-65b5-4cdf-a6a0-c8f8f770ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View  slice from '2023-12-30' to the last row, and from 'STATION' to the last column using iloc (exclusive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a56c1e5-44e9-4799-902a-c6a2993f3585",
   "metadata": {},
   "source": [
    "There are so many ways for slicing through a DataFrame. For more examples and details, check [Introduction to Pandas](https://foundations.projectpythia.org/core/Pandas/Pandas.html) by [Project Pythia](https://projectpythia.org)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d44c1a9-4e7a-48fb-8107-d352f4381d91",
   "metadata": {},
   "source": [
    "### 4.12 Dicing\n",
    "\n",
    "While slicing involves selecting specific rows and columns based on their indices or labels, dicing goes a step further by selecting specific elements based on some condition or criteria. It looks something like this\n",
    "\n",
    "```Python\n",
    "# for multiple conditions and multiple columns to show\n",
    "df.loc[(condtions_on_rows, columns_to_show] \n",
    "```\n",
    " \n",
    "Let us do a simple example investigating extreme values. Find the days where  `'TMIN'<=36`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e326d6a-bbc0-45c8-b3c1-8fc872f0be9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Condition 'TMIN'<=36 (dot notation)\n",
    "\n",
    "\n",
    "#Retriving all data with the above condition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01173f98-1091-480b-9765-92f78722cccf",
   "metadata": {},
   "source": [
    "What we did in the above example, is a mask with a condition that returns Boolean value True when the condition is met and False otherwise.\n",
    "\n",
    "Now let us do another extreme values by have two conditions: `'PRCP'>0` and `'TMAX'>=98`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a58623-0f39-4f3b-84a4-2e4f8a2daecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coditions of 'PRCP'>0 and 'TMAX'>98 (dot notation)\n",
    "\n",
    "#Retriving all data with the above condtions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103a2559-91ba-4416-8d6d-3d5a62471e02",
   "metadata": {},
   "source": [
    "One more argument `[\"column_to_select1\", \"column_to_select2\", ...]` are the columns that you want retrive. For example, suppose we want to know the wwind speed and Station ID when these two conditions 'PRCP'>0 and 'TMAX'>80 are meet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34029fd3-e103-43f6-bc15-85b5a3caf040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coditions of 'PRCP'>0 and 'TMAX'>98 (dot notation)\n",
    "conditions= (two_stations.PRCP>0) & (two_stations.TMAX>=98)\n",
    "\n",
    "# Columns to show \n",
    "columns_to_show = ['AWND','STATION']\n",
    "\n",
    "#Retriving all data with the above condtions and showing selectec columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d441ec53-ebed-4f08-a045-8fdf23df20ba",
   "metadata": {},
   "source": [
    "In the above examples, we used dot notation, but we can also use dic notation. Check [Section 4.8](#4.8-Descriptive-statistics) for more information about the difference between dot and doc notations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f94ec-739f-442e-a7a9-2ae9a961236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coditions of 'PRCP'>0 and 'TMAX'>98 (dic notation)\n",
    "conditions= (two_stations['PRCP']>0) & (two_stations['TMAX']>=98)\n",
    "\n",
    "# Columns to show \n",
    "columns_to_show = ['AWND','STATION']\n",
    "\n",
    "#Retriving all data with the above condtions and showing selectec columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc9bb52-d446-455e-818c-c55890b794bc",
   "metadata": {},
   "source": [
    "### 4.13 Slicing and dicing together\n",
    "\n",
    "You can first slice and then dice and vice verse using chain method. For example, `df.loc[dice].loc[slice]`. \n",
    "\n",
    "For example, retrive wind and station data with `'TMAX'>=96` and `'PRCP'>0` in `2023`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4246378-10de-41f4-ade4-c0df9c220afd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#conditions of 'PRCP'>0 and 'TMAX'>=96\n",
    "conditions= (two_stations[\"PRCP\"] > 0) & (two_stations[\"TMAX\"]>=96)\n",
    "\n",
    "#columns to show\n",
    "columns_to_show= ['STATION','AWND']\n",
    "\n",
    "# Dice to my condition and columns to show -> slice to 2023 that is from '2023-01-01' to '2023-12-31'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fd89d4-93a4-45f5-820f-02b80035bb31",
   "metadata": {},
   "source": [
    "#### Challange your understanding\n",
    "\n",
    "Find the mean wind speed when `'TMAX'>=96` and `'PRCP'>0` in `2023`. This is the same as the above example. But then you need to select column `AWND` using `.AWND`, `['AWND']` , or `.loc[:,'AWND'].`Then do one more chain with the `.mean()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b557c14-99bb-4c07-b5f3-cf40d314f46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conditions of 'PRCP'>0 and 'TMAX'>=96\n",
    "conditions= (two_stations[\"PRCP\"] > 0) & (two_stations[\"TMAX\"]>=96)\n",
    "\n",
    "#columns to show\n",
    "columns_to_show= ['STATION','AWND']\n",
    "\n",
    "# Approach 1 : .AWMD\n",
    "# Dice to my condition and columns to show -> slice to 2023 \n",
    "# -> select AWMD column -> use mean() method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5180842f-e4ee-47f5-a365-c0ebacce090d",
   "metadata": {},
   "source": [
    "You can also try the two other indexing approaches suggested above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f832c2-83ca-4e3b-9d0f-954b631cb772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 2 : ['AWND']\n",
    "# Dice to my condition and columns to show -> slice to 2023 \n",
    "# -> index to AWMD column -> use mean() method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0723ac4-39eb-4c25-a633-1462fe90cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 3 : .loc[:, 'AWND']\n",
    "# Dice to my condition and columns to show -> slice to 2023 \n",
    "# -> index to AWMD column -> use mean() method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675d96ae-8f64-4aa3-b58d-eee6d66c9b19",
   "metadata": {},
   "source": [
    "#### Ask a LLM (opitional)\n",
    "\n",
    "Below are three approaches for finding the mean AWMD for the extrem conditions `PRCP> 0` and `TMAX>=96` in `2023`. Ask a LLM if there are other approaches to find that mean. Here is the prompt that I provided:\n",
    "\n",
    "```\n",
    "Below are three approaches to find that mean of AWND. Can you suggest another approach?\n",
    "    ```Python\n",
    "    #conditions of 'PRCP'>0 and 'TMAX'>=96\n",
    "    conditions= (two_stations[\"PRCP\"] > 0) & (two_stations[\"TMAX\"]>=96)\n",
    "    \n",
    "    #columns to show\n",
    "    columns_to_show= ['STATION','AWND']\n",
    "    \n",
    "    # Approach 1\n",
    "    # Dice to my condition and columns to show -> slice to 2023 \n",
    "    # -> index to AWMD column -> use mean() method\n",
    "    two_stations.loc[conditions, columns_to_show].loc['2023-01-01':'2023-12-31'].AWND.mean()\n",
    "    \n",
    "    # Approach 2\n",
    "    # Dice to my condition and columns to show -> slice to 2023 \n",
    "    # -> index to AWMD column -> use mean() method\n",
    "    two_stations.loc[conditions, columns_to_show].loc['2023-01-01':'2023-12-31']['AWND'].mean()\n",
    "    \n",
    "    #Approach 3 \n",
    "    # Dice to my condition and columns to show -> slice to 2023 \n",
    "    # -> index to AWMD column -> use mean() method\n",
    "    two_stations.loc[conditions, columns_to_show].loc['2023-01-01':'2023-12-31'].loc[:,'AWND'].mean()\n",
    "    ```\n",
    "I am writing in Jupyter notebook using the Python 3 (system-wide) kernel.\n",
    "```\n",
    "\n",
    "I provided the above prompt to ChatGPT 3.5. Here are the responses that I got:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc6cb80-d04b-4534-a3e3-2884e778ca09",
   "metadata": {},
   "source": [
    "ChatGPT 3.5, provided an approach to filter the data and calculate the mean, and suggested to \"choose the method that best fits your coding style and preference.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe9054-12d1-4615-846d-afb46937f284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 4\n",
    "# Use loc to apply conditions, slice to 2023, select the 'AWND' column, and calculate the mean directly\n",
    "two_stations.loc[conditions & (two_stations.index.year == 2023), 'AWND'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b73c80-c33a-4276-a087-fdb06fb7f427",
   "metadata": {},
   "source": [
    "ChatGPT suggested subsetting using Datetime column `.index.year`. This is what we will learn next. However, you can ask your LLM to explain the solution to you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7285ecf0-1931-480f-acd4-75cb8b0f46b0",
   "metadata": {},
   "source": [
    "### 4.14 Subsetting using Datetime Column\n",
    "\n",
    "Slicing as shown in [Section 4.11](#4.11-Slicing-with-loc-and-iloc) is a useful technique for subsetting a DataFrame, but there are also other options that can be equally useful.\n",
    "\n",
    "Before we start, let us first create a fresh copy of our DataFrame, just to review and remember [what we did before](#4.10-Groupby)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f341aa-88f6-4e4e-92d5-ce6f2003e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new DataFrame contains only stations at airports\n",
    "two_stations = df.copy()\n",
    "\n",
    "# Convert the \"DATE\" column to datetime format\n",
    "two_stations['DATE'] = pd.to_datetime(two_stations['DATE'])\n",
    "\n",
    "# Set the \"DATE\" column as the index of your DataFrame\n",
    "two_stations.set_index('DATE', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d1a497-c6b0-4598-8890-dbb035f2333c",
   "metadata": {},
   "source": [
    "If your DataFrame uses datetime values for indices, you can select data from only one day using `df.index.day`, one month using `df.index.month`, one year using `df.index.year`, and so on. \n",
    "\n",
    "For example, the expression \n",
    "```python\n",
    "two_stations.index.month == 12\n",
    "```\n",
    "will create a boolean mask where each element corresponds to whether the month component of the index of each row is equal to 12. In other words, this expression give True for rows where the month is December (i.e., month number 12) and False for rows where the month is not December. This boolean mask can then be used to filter rows based on the condition that the month is December using for example, \n",
    "```python\n",
    "df.loc([two_stations.index.month == 12])\n",
    "```\n",
    "\n",
    "Let us say that we want to calculate the mean of the `TMIN` and `TMAX` columns for the month of December across all years for our`two_stations` DataFrame. How to approach this task? Here is one strategy\n",
    "1. Filter the rows of the `two_stations` DataFrame based on the condition of the month of December as described above\n",
    "2. Select the columns `TMIN` and `TMAX` from the DataFrame using `[['TMIN','TMAX']]`, or `.loc[:, ['TMIN','TMAX']]`\n",
    "3. Apply `.mean()` function to the filtered DataFrame\n",
    "\n",
    "You can also do step 2 column selection before step 1 filtering by month using datetime subset.\n",
    "  \n",
    "Let us try to test both of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0762f38b-e6d6-4b2f-9aeb-5df32d59a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 1 Datetime subset -> Select \n",
    "#Subset condition with datetime index: month == 12 (December)\n",
    "\n",
    "\n",
    "#Subset given my condition -> select columns .loc[:,['TMIN','TMAX']]-> apply .mean() function \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae01037-1869-4ff3-aacd-43d3996f9597",
   "metadata": {},
   "source": [
    "#### Test your understanding \n",
    "Redo the above example, but by applying step 2 that is column selections, before step 1 that is filtering for the month of december."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c38b01-fd16-41d1-a8ca-d2d7120e6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 2 Select -> Datetime subset \n",
    "\n",
    "#Subset condition with datetime index is the month == 12 (December)\n",
    "condition = two_stations.index.month == 12\n",
    "\n",
    "# Select columns .loc[:,['TMIN','TMAX']] -> Subset given my condition -> apply .mean() function \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60843839-c7e6-47fb-b879-c0105ed220be",
   "metadata": {},
   "source": [
    "#### Another example with LLM (*opitional*)\n",
    "\n",
    "Do a for loop to find the mean TMIN and TMAX from Jan to Dec from 2020-01-01 to 2023-12-31. For each iteration print month, TMIN, and TMAX in a table format. To print in table format you can use install the package `tabulate` that can do this for you. We did not learn this package, but you can ask a LLM to solve this problem for you. \n",
    "\n",
    "Here is one prompt:\n",
    "```Note\n",
    "    Do a for loop to find the mean TMIN and TMAX for the study period, using this code \n",
    "    ```Python\n",
    "    #Subset to data in month 12 (December) and get the mean TMIN and TMAX in December throughout the study period \n",
    "    two_stations.loc[:,['TMIN','TMAX']].loc[two_stations.index.month == 12].mean() \n",
    "    ``` \n",
    "    For each iteration print the month name, TMIN, and TMAX in a table format. \n",
    "```\n",
    "This is the solution that I got from ChatGPT 3.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b1b39a-027f-45fa-93cc-2b6ccf92a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install tabulate if you are using it for the first time by uncommenting the pip install command\n",
    "#pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ca3820-6e65-4be2-84f3-9e3f68fb1af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT 3.5 Solution\n",
    "#Import two modules\n",
    "import calendar\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate over each month\n",
    "for month in range(1, 13):\n",
    "\n",
    "    #Subset condition with datetime index is the month == 12 (December)\n",
    "    condition= two_stations.index.month == month\n",
    "    \n",
    "    # Subset data for the current month and calculate mean TMIN and TMAX\n",
    "    monthly_data = two_stations.loc[:, ['TMIN', 'TMAX']].loc[condition,:]\n",
    "    mean_TMIN = monthly_data['TMIN'].mean()\n",
    "    mean_TMAX = monthly_data['TMAX'].mean()\n",
    "    \n",
    "    # Get month name\n",
    "    month_name = calendar.month_name[month]\n",
    "    \n",
    "    # Append the results to the list\n",
    "    results.append([month_name, round(mean_TMIN, 2), round(mean_TMAX, 2)])\n",
    "\n",
    "# Print results in table format\n",
    "print(tabulate(results, headers=[\"Month\", \"Mean TMIN\", \"Mean TMAX\"], tablefmt=\"pretty\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496928e5-f52f-4d1c-b0dd-543f5eb8369b",
   "metadata": {},
   "source": [
    "#### A comprehensive example (*advanced*)\n",
    "\n",
    "Let us look at an example where we can apply many of the methods that we learned. Let use reslove the above problem without using loops. We can use something that we learned before like  [groupby](#4.10-Groupby). Remember groupby is tool for grouping data based on some criteria, which can include time-related criteria but is not limited to time-series data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806f8a90-e983-4e65-a05d-da419e8b9204",
   "metadata": {},
   "source": [
    "Here is a solution strategy \n",
    "1. Use something like `.index.month` to find the month number for each row\n",
    "2. Add the month number for each row as a new column, e.g., 'month'\n",
    "3. Select the columns 'TMIN', 'TMAX', 'month': `[['TMIN','TMAX', 'month']]` or `.loc[:, ['TMIN','TMAX','month']]`\n",
    "4. Groupby by 'month': `.groupby('month')`\n",
    "5. Apply `.mean()` function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82715f76-6078-44aa-ab91-a001dc94ad60",
   "metadata": {},
   "source": [
    "So far we have used the DataFrame as is without adding or removing a column to the DataFrame. Let us now add to `two_stations` a new column 'month'. The value returned by `df.index.month` is used to obtain the data for this new column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc0afc-2a9c-4017-b089-3c1b51b8153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add new column 'month' with its values obtained from index\n",
    "two_stations['month'] = two_stations.index.month\n",
    "\n",
    "#Display new DataFrame\n",
    "two_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb417f59-ca3f-4c2e-959a-146e9099e14b",
   "metadata": {},
   "source": [
    "Select the columns that you want to apply groupby to. Then groupby month and the apply `.mean()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d72605-5bee-4b26-a20b-46d8c1e8b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns ->  Groupby month -> Apply mean to find the mean for each month\n",
    "two_stations.loc[:, ['TMIN','TMAX','month']].groupby('month').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2cd421-e570-4785-9439-58acd12ceac6",
   "metadata": {},
   "source": [
    "In the above example, I solved the problem in five steps through adding the new column `month` for illustration purpose. You can only solve it in three steps without adding the new column `month` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92b7b72-d709-4917-a5d9-d6f4189ff009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns ->  Groupby month -> Apply mean to find the mean for each month\n",
    "two_stations.loc[:, ['TMIN','TMAX']].groupby(two_stations.index.month).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e92b72e-f2f0-404c-a47f-9b4f5dff03c8",
   "metadata": {},
   "source": [
    "How can you customize your table to look like the table you got in the [above example with loop](#-Another-example-with-LLM-(*opitional*)). I asked ChatGPT 3.5, and here is what I got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266f4405-b724-4edd-960e-142fac295202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "# Select columns, group by month, and apply mean to find the mean for each month\n",
    "monthly_means = two_stations.loc[:, ['TMIN', 'TMAX']].groupby(two_stations.index.month).mean()\n",
    "\n",
    "# Map month numbers to month names\n",
    "monthly_means.index = monthly_means.index.map(lambda x: calendar.month_name[x])\n",
    "\n",
    "# Round mean values to two decimal points\n",
    "monthly_means = monthly_means.round(2)\n",
    "\n",
    "# Rename the columns\n",
    "monthly_means = monthly_means.rename(columns={'TMIN': 'Mean TMIN', 'TMAX': 'Mean TMAX'})\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "display(monthly_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f188f2-853a-4cea-921d-c15e2af6945b",
   "metadata": {},
   "source": [
    "In the code above we learned everything expect for `.map()` and `lambda` function. You can ask your LLM to learn more about this. However, if you can understand that much, you have a very good understanding of Pandas and Python in general."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5df62e-6077-473d-9f5b-b1a88499ce43",
   "metadata": {},
   "source": [
    "### 4.15 Quick Plots of Your Data\n",
    "A good way to explore your data is by making a simple plot. Pandas contains its own `.plot` method; this allows us to plot Pandas series without needing `matplotlib`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9dfda1-f66b-4d9c-8cc1-357c62428647",
   "metadata": {},
   "source": [
    "#### 4.15.1 Line plot\n",
    "\n",
    "This is very simply:\n",
    "```python\n",
    "df[columns_to_plot].plot(opitions_as_needed)\n",
    "```\n",
    "\n",
    "In this example, we plot the `TMAX` and `TMIN` series of our DataFrame with lin plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c329f0d5-83a8-4353-9dac-974406b53d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select data to plot: TMAX and TMIN\n",
    "data_to_plot=['TMAX','TMIN']\n",
    "\n",
    "#Plot method: .plot();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09808352-5daf-4f89-a5f4-f9e306e52aa7",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Note</p>\n",
    "Prompt engineering entails crafting precise prompts to guide a large language model (LLM) to generate desired outputs. Mastering prompt engineering enables effective utilization of LLMs across tasks from problem-solving to creative writing. Learn more with Real Python's tutorial on Prompt Engineering: A Practical Example.\n",
    "\n",
    "Prompt engineering involves crafting precise and effective prompts or instructions to guide a large language model (LLM) to generat the desired outputs. Learning prompt engineering, through providing clear guidance and constraints, will help you to effectively harness the capabilities of LLMs for various tasks from creative writing to problem-solving. To learn prompt engineering you can check for example <a href=\"https://realpython.com/practical-prompt-engineering/\">Prompt Engineering: A Practical Example</a> tutorial by Real Python. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73e1f4e-0037-4ba2-b636-8f3e514fec43",
   "metadata": {},
   "source": [
    "#### 4.15.2 Histogram plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f013e9b-742d-4291-ab12-b12db6bca151",
   "metadata": {},
   "source": [
    "In the previous example we called `.plot()`, which generated a single line plot. Line plots can be helpful for understanding some types of data, but there are other types of data that can be better understood with different plot types. For example, if you want to see the distribution of your data, you can better do this with a histogram plot.\n",
    "\n",
    "Let us do something more advanced than the previous example to build on what we learned before. Let use say we want to see the `TMAX` distributions for years `2022` and `2023`. That is tricky. Let us think about this step-by-step. First we need to create two new columns `2022_TMAX` and `2023_TMAX`, such that `2022_TMAX` will contain `TMAX` data for `2022`, and `2023_TMAX` will contain `TMAX` data for `2023`. Then we can plot the data of these two new columns.\n",
    "\n",
    "We have learned how to do this before with [Slicing](#-4.11-Slicing-with-loc-and-iloc) and with [Subsetting](#-4.14-Subsetting-using-Datetime-Column). Here is how to do this with [Slicing](#-4.11-Slicing-with-loc-and-iloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5475f65-6c0a-48bb-b117-b9d21122b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slicing data for 2022 and 2023 and adding it to the DataFrame\n",
    "one_station['2022_TMAX'] =  one_station.TMAX.loc['2022']\n",
    "one_station['2023_TMAX'] =  one_station.TMAX.loc['2023']\n",
    "\n",
    "# Display updated DataFrame to show the two new columns '2022_TMAX' and '2023_TMAX'\n",
    "one_station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bc4fa8-340e-426a-9206-58439200a235",
   "metadata": {},
   "source": [
    "Let use delete these two columns and add them again with the subsetting method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8679ca3f-bbd9-4723-a91f-49d644e4dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the specified columns from the DataFrame\n",
    "one_station.drop(columns= ['2022_TMAX', '2023_TMAX'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7692a3-79fa-48fb-91ff-5123b5cdf8c9",
   "metadata": {},
   "source": [
    "Now add these two columns back using the subsetting method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2109e0-966b-48c4-866f-bca914831abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subsetting 2022 and 2023 data and adding it to the DataFrame\n",
    "one_station['2022_TMAX'] =  one_station.TMAX.loc[one_station.index.year == 2022]\n",
    "one_station['2023_TMAX'] =  one_station.TMAX.loc[one_station.index.year == 2023]\n",
    "\n",
    "# Display updated DataFrame to show the two new columns '2022_TMAX' and '2023_TMAX'\n",
    "one_station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05359622-25f1-4cf1-a9f1-59802b6862ea",
   "metadata": {},
   "source": [
    "Now we have our data ready for plotting.\n",
    "\n",
    "The code for plotting histogram data is slighlty differs from the code for line plot. After calling the `.plot` method, we call an additional method called `.hist`, which converts the plot into a histogram. Also, we are calling `.hist` with two additional opitional parameters. The first parameter `alpha` is for adjusting the transparency. For example, alpha=0.5 sets the transparency level of the plotted histogram to 50%. The parameter `bins` specifies the number of bins used to divide the range of the data into equal intervals for plotting the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efbbacb-7453-40e6-a152-042c0594ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select data to plot\n",
    "data_to_plot=['2022_TMAX','2023_TMAX']\n",
    "\n",
    "#Histogram method .plot.hist(); with alpha=0.5, bins=20 (alpha parameter for transparency) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56168d5f-9272-4433-9fdd-a7eafea81bab",
   "metadata": {},
   "source": [
    "#### 4.15.3 Box plot\n",
    "\n",
    "The histogram plot helped us to look differently at the data. It seems that the two datasets are from the same distribution. To even better understand this data, it may also be helpful to create a box plot. This can be done using the same code, with one change: we call the `.box` method instead of `.hist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d6e584-3c91-4917-a241-9f28eaeeeef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select data to plot\n",
    "data_to_plot=['2022_TMAX','2023_TMAX']\n",
    "\n",
    "#Box method .plot.box();\n",
    "one_station[data_to_plot].plot.box();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7911129e-1b88-4c71-bdcb-6d7410fe78c9",
   "metadata": {},
   "source": [
    "Just like the histogram plot, this box plot indicates no clear difference in the distributions. Using multiple types of plot in this way can be useful for verifying large datasets. The Pandas plotting methods are capable of creating many different types of plots. To see how to use the plotting methods to generate each type of plot, please review the [Pandas plot documentation](https://Pandas.pydata.org/docs/reference/api/Pandas.DataFrame.plot.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7897a2db-d783-4ae4-8f2d-e10815cb32ec",
   "metadata": {},
   "source": [
    "#### 4.15.4 Customize your Plot\n",
    "The Pandas plotting methods are, in fact, wrappers for similar methods in matplotlib.  This means that you can customize Pandas plots by including keyword arguments to the plotting methods.  These keyword arguments, for the most part, are equivalent to their matplotlib counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7bacd2-dfc0-4814-ae73-38f0b1cedc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plain plotting without customization\n",
    "one_station[['TMAX','TMIN']].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ace3a1-abef-4f3b-b460-830fbe99f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here are some customizations that you can do \n",
    "one_station[['TMAX', 'TMIN']].plot(\n",
    "    color=['red', 'blue'],          # Set different colors for TMAX and TMIN\n",
    "    linewidth=1,                  # Set the width of the lines to 1\n",
    "    xlabel='Date',                 # Set the label for the x-axis\n",
    "    ylabel='Temperature (deg F)',   # Set the label for the y-axis\n",
    "    figsize=(12, 4),                  # Set the size of the figure to (8, 6) inches\n",
    "    title='Max and Min Temperature Over Time',  # Add a title to the plot\n",
    "    grid=False,                      # Do not show gridlines on the plot\n",
    "    legend=True,                    # Show a legend\n",
    "    style=['-', '-'],              # Set solid line for TMAX and TMIN\n",
    "    alpha=0.8,                      # Set the transparency of the lines to 0.8\n",
    "    xlim=('2020-01-01', '2024-01-01'),  # Set the limits for the x-axis\n",
    "    ylim=(30, None),                 # Set the lower limit for the y-axis to 0\n",
    "    rot=0,                         # Rotate x-axis labels by 0 degrees\n",
    "    fontsize=12,                    # Set font size for labels\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab375ec-0e55-4bd1-adfd-684b03e0bb3e",
   "metadata": {},
   "source": [
    "### 4.16 Applying operations to a DataFrame\n",
    "\n",
    "One of the most commonly used features in Pandas is the performing of calculations to multiple data values in a `DataFrame` simultaneously. Let's first look at a a function that converts temperature values from degrees Fahrenheit  to Celsius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc8fa8-84df-4943-a814-4f3b1c7386b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fahrenheit_to_celsius(temp_ferh):\n",
    "    \"\"\"\n",
    "    Converts from degrees Fahrenheit to Celsius.\n",
    "    \"\"\"\n",
    "    return (temp_ferh - 32) * 5/9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b14ed1-9ace-430f-850f-83235fa1b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test your function here be checking freezing point temp_Fehr=32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8b318-191c-4ca5-aae4-3f21cfc655c1",
   "metadata": {},
   "source": [
    "Let us create a new DataFrame for temperature data and apply `ferhenirt_to_celsius` function to convert data from Ferhenirt to Celsius. Then add the new data as two new columns `TMAX_C` and `TMIN_C`. This can take this form: \n",
    "```python\n",
    "df[new_columns] = my_function(df[original_columns])\n",
    "```\n",
    "\n",
    "Also, rename the original `TMAX` to `TMAX_F` and `TMIN` to `TMIN_F`. For renaming you can use the rename function:\n",
    "```python\n",
    "df = df.rename(columns={'old_name1': 'new_name1', 'old_name2': 'new_name2'})\n",
    "```\n",
    "Here is how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcadde8-abf5-43c9-b91d-d4fbe4ed96e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame for temp values TMAX and TMIN\n",
    "temp=one_station[['TMAX','TMIN']].copy()\n",
    "\n",
    "# Convert temp from F to C and save to new columns TMAX_C and TMIN_C\n",
    "\n",
    "\n",
    "#Change the name of TMAX to TMAX_F and TMIN to TMIN_F\n",
    "\n",
    "# Display new DataFrame \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850506c7-df94-47d0-a1c7-0acf5a0cef10",
   "metadata": {},
   "source": [
    "Another way of doing this is to use `.apply()` such that\n",
    "```python\n",
    "df[new_columns] = df[original_columns].apply(my_function)\n",
    "```\n",
    "Try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e3cb48-0746-4f34-8c8e-0488dc50c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame for temp values TMAX and TMIN\n",
    "temp=one_station[['TMAX','TMIN']].copy()\n",
    "\n",
    "# Convert temp from F to C and save to new columns TMAX_C and TMIN_C\n",
    "\n",
    "\n",
    "#Change the name of TMAX to TMAX_F and TMIN to TMIN_F\n",
    "temp = temp.rename(columns={'TMAX': 'TMAX_F', 'TMIN': 'TMIN_F'})\n",
    "\n",
    "# Display new DataFrame \n",
    "display(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe8a93b-9ee9-4c11-9ca2-df0dcaca6a5b",
   "metadata": {},
   "source": [
    "This is just the beginning. You can convert a Pandas DataFrame to numpy array for more advanced array operations. You can do this conversion using the method `.values`.\n",
    "\n",
    "Check the type of your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae99e81-bd97-4b06-9cd7-406488d0783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62579b4a-9ce5-4c6c-a27b-5c01bc22c686",
   "metadata": {},
   "source": [
    "Now use the method `temp.values` and check the type again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629a2e03-0aac-4280-878b-4ba16effe0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(temp.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded7994a-210e-4fdc-95a6-e8e3b717a630",
   "metadata": {},
   "source": [
    "We will learn later learn Numpy, whihc handles multi-dimensional arrays with extensive collection of mathematical functions, facilitating high-performance numerical computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff52ba3-41fd-4bad-ac1c-639921d2e947",
   "metadata": {},
   "source": [
    "### 4.17 Iterating over rows (*opitional*)\n",
    "\n",
    "We can apply a function row at a time using a for loop and the `iterrows()` method. This will allow us to iterate row by row using iterrows() in a for loop to repeat a given process for each row in a Pandas DataFrame. Please note that iterating over rows is a rather inefficient approach, but this is your last resort when the other methods cannot do what you need. \n",
    "\n",
    "Let's start with a simple for loop that goes through each row in our DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a55757f-b8bb-470f-b073-943b092b8135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame for temp values TMAX and TMIN\n",
    "temp=one_station.loc['2023-12-29':'2023-12-31', ['TMAX','TMIN']].copy()\n",
    "\n",
    "# Iterate over the rows\n",
    "for idx, row in temp.iterrows():\n",
    "\n",
    "    # Print the index value\n",
    "    display(idx)\n",
    "\n",
    "    # Print the row\n",
    "    display(row['TMAX'])\n",
    "    display(row['TMIN'])\n",
    "\n",
    "    break   #Break is used to show only the first iteration of the for loop for testing purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea828784-e269-4f71-90c9-087f5b15a9ca",
   "metadata": {},
   "source": [
    "Now for each value let use apply our `fahrenheit_to_celsius` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f23d8dc-cf8a-4b07-b700-bd5f63460594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame for temp values TMAX and TMIN\n",
    "temp=one_station[['TMAX','TMIN']].copy()\n",
    "\n",
    "# Iterate over the rows\n",
    "for idx, row in temp.iterrows():\n",
    "    # Convert TMAX from Fahrenheit to Celsius\n",
    "    temp.loc[idx, 'TMAX_C'] = fahrenheit_to_celsius(row['TMAX'])\n",
    "    # Convert TMIN from Fahrenheit to Celsius\n",
    "    temp.loc[idx, 'TMIN_C'] = fahrenheit_to_celsius(row['TMIN'])\n",
    "\n",
    "#Change the name of TMAX to TMAX_F and TMIN to TMIN_F\n",
    "temp = temp.rename(columns={'TMAX': 'TMAX_F', 'TMIN': 'TMIN_F'})\n",
    "\n",
    "# Display the resulting DataFrame with temperatures converted to Celsius\n",
    "display(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae94f54-de4b-436d-a884-e641fbdbe4be",
   "metadata": {},
   "source": [
    "### 4.18 Save and load your DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164917b2-6ea4-4bc8-925d-c1c3b06b7663",
   "metadata": {},
   "source": [
    "In this final example, we demonstrate the use of the `to_csv` method to save a DataFrame as a `.csv` file. This example also demonstrates the `read_csv` method, which reads `.csv` files into Pandas `DataFrames`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863e43c8-d0e9-4e4f-be07-16233d36179c",
   "metadata": {},
   "source": [
    "#### 4.18.1 Save a DataFrame as `.csv` file\n",
    "\n",
    "The `to_csv` method saves a DataFrame as a `.csv` file as\n",
    "```python\n",
    "df.to_csv('file_path/file_name.csv')\n",
    "```\n",
    "Try to to save your `temp` DataFrame to 'temp_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be029941-ecf2-49b0-857c-ef1900014e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your temp data in F and C to a CSV file 'temp_data.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d16118-f62d-4dec-9f52-5af1d49eddac",
   "metadata": {},
   "source": [
    "#### 4.18.2 Read a `.csv` files into DataFrames\n",
    "\n",
    "We want to\n",
    "1. read the file as new DataFrame called `df_temp`, \n",
    "2. set our first column as our index column,\n",
    "3. and change the format of our index to datetime format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd121ca-e040-417d-98df-4139f26ae94e",
   "metadata": {},
   "source": [
    "Let us break it down part by part.\n",
    "\n",
    "First, you can use the `read_csv` method reads `.csv` files into Pandas DataFrames\n",
    "```python\n",
    "df_name= pd.read_csv('file_path/file_name.csv', index_col = 0, parse_dates = True )\n",
    "```\n",
    "\n",
    "Second, set the the first column which contain datetime data as our index using:\n",
    "```python\n",
    "index_col = 0\n",
    "```\n",
    "which specifies that the first column of the CSV file should be used as the index of the DataFrame. If you want for example to use your third column as the index of your DataFrame, you can do `index_col = 2` and so on. \n",
    "\n",
    "Third, parse any date-like columns as datetime objects using\n",
    "```python \n",
    "parse_dates = True \n",
    "```\n",
    "which instructs Pandas to attempt to parse any datetime columns including index in the CSV file as datetime objects.\n",
    "\n",
    "Here is how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836dd8b-f74d-435c-9eaf-0325e9d901bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file as a new DataFrame 'df_temp', and set first column as index with datetime format\n",
    "\n",
    "\n",
    "#Display your new DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b6292-3a65-42b2-8a90-a5e7db5b3d4b",
   "metadata": {},
   "source": [
    "What we did not learn so far is how to create a DataFrame from a given data rather than reading it from a file. You can learn this on your own. Ask a LLM for example and guide yourself through the learning process. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e01f4d-707f-4e2f-8e43-a13d62b70035",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "## Summary\n",
    "* Pandas is a very powerful tool for working with tabular (i.e., spreadsheet-style) data\n",
    "* There are multiple ways of subsetting your Pandas dataframe or series\n",
    "* Pandas allows you to refer to subsets of data by label, which generally makes code more readable and more robust\n",
    "* Pandas can be helpful for exploratory data analysis, including plotting and basic statistics\n",
    "* One can apply calculations to Pandas dataframes and save the output via `csv` files\n",
    "\n",
    "### What's Next?\n",
    "To learn Pandas, you do not need to read more, but to practice more. Start working on your homework. When encountering challenges, refer back to this notebook and seek assistance from a LLM.  If the LLM provided a new method that you do not understand, ask for explanation. When you write a code that does not work, ask for debugging. Practice as much as you can to learn this powerful data analysis tool. \n",
    "\n",
    "## Resources and References\n",
    "1. [Getting Started with Pandas](https://Pandas.pydata.org/docs/getting_started/index.html#getting-started)\n",
    "1. [Pandas User Guide](https://Pandas.pydata.org/docs/user_guide/index.html#user-guide)\n",
    "1. [Python for Data Analysis, 3rd Edition](https://wesmckinney.com/book/)\n",
    "1. [Introduction to Pandas](https://foundations.projectpythia.org/core/pandas/pandas.html) by [Project Pythia](https://projectpythia.org), "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
